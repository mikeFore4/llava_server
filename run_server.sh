python3 -m llama_cpp.server --model ggml_llava-v1.5-7b/ggml-model-q4_k.gguf --clip_model_path ggml_llava-v1.5-7b/mmproj-model-f16.gguf --chat_format llava-1-5 --host 0.0.0.0
